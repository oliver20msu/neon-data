{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e310b14-856f-4f73-ae7f-d2024ad56826",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio\n",
    "import gradio as gr\n",
    "def greet(name, intensity):\n",
    "  return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "demo = gr.Interface(\n",
    "  fn=greet,\n",
    "  inputs=[\"text\", \"slider\"],\n",
    "  outputs=[\"text\"],\n",
    ")\n",
    "demo.launch(server_name=\"127.0.0.1\", server_port= 7860)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a691c1-3d65-4fac-b998-aa700ff64c0d",
   "metadata": {},
   "source": [
    "## Or, level up your game..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2189268-5c59-401e-b792-e51960d745cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name, intensity):\n",
    "    \"\"\"\n",
    "    Generates a greeting message with an intensity factor.\n",
    "    \"\"\"\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "# Define custom CSS for styling the Gradio app\n",
    "custom_css = \"\"\"\n",
    "/* Import the 'Comfortaa' font from Google Fonts */\n",
    "@import url('https://fonts.googleapis.com/css2?family=Comfortaa:wght@400;700&display=swap');\n",
    "\n",
    "/* Apply the imported font to the entire body of the Gradio app */\n",
    "body {\n",
    "    font-family: 'Comfortaa', cursive;\n",
    "}\n",
    "\n",
    "/* Style the main Gradio container with a lime green background */\n",
    ".gradio-container {\n",
    "    background-color: #90EE90 !important; /* Lime Green */\n",
    "    border-radius: 12px; /* Add some rounded corners to the main container */\n",
    "    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2); /* Add a subtle shadow */\n",
    "}\n",
    "\n",
    "/* Style all Gradio buttons */\n",
    ".gradio-button {\n",
    "    border-radius: 8px !important; /* Rounded corners for buttons */\n",
    "    font-weight: bold !important; /* Make button text bold */\n",
    "    color: #FF69B4 !important; /* Ensure text is visible on colored buttons */\n",
    "    padding: 10px 20px !important; /* Add some padding */\n",
    "    transition: background-color 0.3s ease, transform 0.2s ease; /* Smooth transitions */\n",
    "    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1) !important; /* Add a subtle shadow */\n",
    "}\n",
    "\n",
    "/* Style secondary buttons (e.g., clear button) with grey */\n",
    ".gradio-button:not(.primary) {\n",
    "    background-color: #808080 !important; /* Grey */\n",
    "    border: 1px solid #696969 !important; /* Darker grey border */\n",
    "}\n",
    "\n",
    "/* Style primary buttons (e.g., submit button) with pink */\n",
    ".gradio-button.primary {\n",
    "    background-color: #FF69B4 !important; /* Pink */\n",
    "    border: 1px solid #FF1493 !important; /* Darker pink border */\n",
    "}\n",
    "\n",
    "/* Hover effects for buttons */\n",
    ".gradio-button:hover {\n",
    "    transform: translateY(-2px); /* Lift button slightly on hover */\n",
    "    box-shadow: 0 6px 10px rgba(0, 0, 0, 0.15) !important; /* Enhance shadow on hover */\n",
    "}\n",
    "\n",
    "/* Focus styles for input elements for better accessibility and visual feedback */\n",
    ".gradio-input:focus, .gradio-slider:focus {\n",
    "    border-color: #FF69B4 !important; /* Pink border on focus */\n",
    "    box-shadow: 0 0 0 3px rgba(255, 105, 180, 0.5) !important; /* Pink glow on focus */\n",
    "    outline: none !important; /* Remove default outline */\n",
    "}\n",
    "\n",
    "/* Style labels for better readability */\n",
    ".gradio-label {\n",
    "    font-weight: 700; /* Bold labels */\n",
    "    color: #333; /* Darker text for labels */\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create a Gradio Interface\n",
    "demo_interface = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Your Name\", placeholder=\"Type your name here...\", elem_classes=\"gradio-input\"),\n",
    "        gr.Slider(minimum=1, maximum=10, step=1, label=\"Intensity (1-10)\", elem_classes=\"gradio-slider\")\n",
    "    ],\n",
    "    outputs=[gr.Textbox(label=\"Greeting Message\")],\n",
    "    # No need to pass CSS here directly, it's handled by gr.Blocks\n",
    ")\n",
    "\n",
    "# Use gr.Blocks to apply custom CSS\n",
    "with gr.Blocks(css=custom_css, title=\"Custom Gradio App\") as demo:\n",
    "    gr.Markdown(\"# Welcome to Your Custom Gradio App!\")\n",
    "    gr.Markdown(\"Enter your name and an intensity to see a personalized greeting.\")\n",
    "    demo_interface.render() # Render the interface within the Blocks context\n",
    "\n",
    "# Launch the Gradio application\n",
    "demo.launch(server_name=\"127.0.0.1\", server_port=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51250594-896a-4842-8b42-952f1d6aaad9",
   "metadata": {},
   "source": [
    "## OR EVEN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d475d-ff7e-4211-addb-7399f2202cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greet(name, intensity):\n",
    "    \"\"\"\n",
    "    Generates a greeting message with an intensity factor.\n",
    "    \"\"\"\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "# Define custom CSS for styling the Gradio app\n",
    "custom_css = \"\"\"\n",
    "/* Import the 'Comfortaa' font from Google Fonts */\n",
    "@import url('https://fonts.googleapis.com/css2?family=Comfortaa:wght@400;700&display=swap');\n",
    "\n",
    "/* Apply the imported font to the entire body of the Gradio app */\n",
    "body {\n",
    "    font-family: 'Comfortaa', cursive;\n",
    "}\n",
    "\n",
    "/* Style the main Gradio container with a lime green background */\n",
    ".gradio-container {\n",
    "    background-color: #90EE90 !important; /* Lime Green */\n",
    "    border-radius: 12px; /* Add some rounded corners to the main container */\n",
    "    box-shadow: 0 8px 16px rgba(0, 0, 0, 0.2); /* Add a subtle shadow */\n",
    "}\n",
    "\n",
    "/* Style all Gradio buttons */\n",
    ".gradio-button {\n",
    "    border-radius: 8px !important; /* Rounded corners for buttons */\n",
    "    font-weight: bold !important; /* Make button text bold */\n",
    "    color: white !important; /* Ensure text is visible on colored buttons */\n",
    "    padding: 10px 20px !important; /* Add some padding */\n",
    "    transition: background-color 0.3s ease, transform 0.2s ease; /* Smooth transitions */\n",
    "    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1) !important; /* Add a subtle shadow */\n",
    "}\n",
    "\n",
    "/* Style secondary buttons (e.g., clear button) with grey */\n",
    ".gradio-button:not(.primary) {\n",
    "    background-color: #808080 !important; /* Grey */\n",
    "    border: 1px solid #696969 !important; /* Darker grey border */\n",
    "}\n",
    "\n",
    "/* Style primary buttons (e.g., submit button) with pink */\n",
    "/* This rule is kept as a fallback, but the theme's primary_hue is now more effective */\n",
    ".gradio-button.primary {\n",
    "    background-color: #FF69B4 !important; /* Pink */\n",
    "    border: 1px solid #FF1493 !important; /* Darker pink border */\n",
    "}\n",
    "\n",
    "/* Hover effects for buttons */\n",
    ".gradio-button:hover {\n",
    "    transform: translateY(-2px); /* Lift button slightly on hover */\n",
    "    box-shadow: 0 6px 10px rgba(0, 0, 0, 0.15) !important; /* Enhance shadow on hover */\n",
    "}\n",
    "\n",
    "/* Focus styles for input elements for better accessibility and visual feedback */\n",
    ".gradio-input:focus, .gradio-slider:focus {\n",
    "    border-color: #FF69B4 !important; /* Pink border on focus */\n",
    "    box-shadow: 0 0 0 3px rgba(255, 105, 180, 0.5) !important; /* Pink glow on focus */\n",
    "    outline: none !important; /* Remove default outline */\n",
    "}\n",
    "\n",
    "/* Style labels for better readability */\n",
    ".gradio-label {\n",
    "    font-weight: 700; /* Bold labels */\n",
    "    color: #333; /* Darker text for labels */\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Create a Gradio Interface\n",
    "demo_interface = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Your Name\", placeholder=\"Type your name here...\", elem_classes=\"gradio-input\"),\n",
    "        gr.Slider(minimum=1, maximum=10, step=1, label=\"Intensity (1-10)\", elem_classes=\"gradio-slider\")\n",
    "    ],\n",
    "    outputs=[gr.Textbox(label=\"Greeting Message\")],\n",
    "    # No need to pass CSS here directly, it's handled by gr.Blocks\n",
    ")\n",
    "\n",
    "# Use gr.Blocks to apply custom CSS and a custom theme\n",
    "with gr.Blocks(\n",
    "    css=custom_css,\n",
    "    title=\"Custom Gradio App\",\n",
    "    # Set the primary hue of the theme to Pink for primary elements like the Submit button\n",
    "    theme=gr.themes.Base(primary_hue=gr.themes.colors.pink) # Corrected: removed parentheses\n",
    ") as demo:\n",
    "    gr.Markdown(\"# Welcome to Your Custom Gradio App!\")\n",
    "    gr.Markdown(\"Enter your name and an intensity to see a personalized greeting.\")\n",
    "    demo_interface.render() # Render the interface within the Blocks context\n",
    "\n",
    "# Launch the Gradio application\n",
    "demo.launch(server_name=\"127.0.0.1\", server_port=3660)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78d17b5-ca72-4beb-a00a-f9e1e6b7d0e8",
   "metadata": {},
   "source": [
    "## Parse all images on a website and caption them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a975dafa-d124-4154-9343-a7d1054931c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers import AutoProcessor, BlipForConditionalGeneration\n",
    "# Load the pretrained processor and model\n",
    "processor = AutoProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "# URL of the page to scrape\n",
    "url = \"https://en.wikipedia.org/wiki/IBM\" # This is the website for which you want to caption images\n",
    "# Download the page\n",
    "response = requests.get(url)\n",
    "# Parse the page with BeautifulSoup\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# Find all img elements\n",
    "img_elements = soup.find_all('img')\n",
    "# Open a file to write the captions\n",
    "with open(\"captions.txt\", \"w\") as caption_file: # This is the file name you want your results written as\n",
    "    # Iterate over each img element\n",
    "    for img_element in img_elements:\n",
    "        img_url = img_element.get('src')\n",
    "        # Skip if the image is an SVG or too small (likely an icon)\n",
    "        if 'svg' in img_url or '1x1' in img_url:\n",
    "            continue\n",
    "        # Correct the URL if it's malformed\n",
    "        if img_url.startswith('//'):\n",
    "            img_url = 'https:' + img_url\n",
    "        elif not img_url.startswith('http://') and not img_url.startswith('https://'):\n",
    "            continue  # Skip URLs that don't start with http:// or https://\n",
    "        try:\n",
    "            # Download the image\n",
    "            response = requests.get(img_url)\n",
    "            # Convert the image data to a PIL Image\n",
    "            raw_image = Image.open(BytesIO(response.content))\n",
    "            if raw_image.size[0] * raw_image.size[1] < 400:  # Skip very small images\n",
    "                continue\n",
    "            raw_image = raw_image.convert('RGB')\n",
    "            # Process the image\n",
    "            inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "            # Generate a caption for the image\n",
    "            out = model.generate(**inputs, max_new_tokens=50)\n",
    "            # Decode the generated tokens to text\n",
    "            caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "            # Write the caption to the file, prepended by the image URL\n",
    "            caption_file.write(f\"{img_url}: {caption}\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {img_url}: {e}\")\n",
    "            continue\n",
    "\n",
    "#NB: Your results will be written to a .txt file and saved locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cad3df1-e5bd-4ae7-a115-b7f2d2e0e8a4",
   "metadata": {},
   "source": [
    "## Caption all images in a local file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d028e7e-e3c7-45c3-b81d-dabfe37da72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6828def3e8042b1bd9d9b095d034b89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Caption local image files using BLIP-2 model\n",
    "# This script generates captions for local image files using the BLIP-2 model from Hugging Face.\n",
    "import os\n",
    "import glob\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration #Blip2 models\n",
    "# Load the pretrained processor and model\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "# Specify the directory where your images are\n",
    "image_dir = r\"C:\\Users\\oliver20\\OneDrive - BYU-Idaho\\Pictures\"  # Change this to your image directory\n",
    "image_exts = [\"jpg\", \"jpeg\", \"png\"]  # specify the image file extensions to search for\n",
    "# Open a file to write the captions\n",
    "with open(\"local_captions.txt\", \"w\") as caption_file: # Specify the name you want for the .txt file that will be written\n",
    "    # Iterate over each image file in the directory\n",
    "    for image_ext in image_exts:\n",
    "        for img_path in glob.glob(os.path.join(image_dir, f\"*.{image_ext}\")):\n",
    "            # Load your image\n",
    "            raw_image = Image.open(img_path).convert('RGB')\n",
    "            # You do not need a question for image captioning\n",
    "            inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "            # Generate a caption for the image\n",
    "            out = model.generate(**inputs, max_new_tokens=50)\n",
    "            # Decode the generated tokens to text\n",
    "            caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "            # Write the caption to the file, prepended by the image file name\n",
    "            caption_file.write(f\"{os.path.basename(img_path)}: {caption}\\n\")\n",
    "\n",
    "#NB: Your results will be written to a .txt file as specified in this code\n",
    "## Could level this up by putting image_dir = 'file_directory' and 'your_desired_output_file_name' in place of the file name. \n",
    "## Then make a gradio app that asks for two fields: What is the directory name for files you would like to caption?\n",
    "## What would you like to name the output file?\n",
    "## Then just run an index.html and a js file that references passing these on to the python code and delivering back the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b069608-d51e-461c-802c-9a8019808759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicker version (gives updates as it works)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import requests\n",
    "from PIL import Image\n",
    "from transformers import Blip2Processor, Blip2ForConditionalGeneration\n",
    "\n",
    "# Load the pretrained processor and model\n",
    "processor = Blip2Processor.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "model = Blip2ForConditionalGeneration.from_pretrained(\"Salesforce/blip2-opt-2.7b\")\n",
    "\n",
    "# Specify the directory where your images are\n",
    "image_dir = r\"C:\\Users\\oliver20\\OneDrive - BYU-Idaho\\Pictures\"  # Change this to your image directory\n",
    "image_exts = [\"jpg\", \"jpeg\", \"png\"]  # specify the image file extensions to search for\n",
    "\n",
    "# Open a file to write the captions\n",
    "with open(\"local_captions.txt\", \"w\") as caption_file:\n",
    "    # Iterate over each image file in the directory\n",
    "    for image_ext in image_exts:\n",
    "        # Use glob.iglob for potentially large directories, which yields paths one by one\n",
    "        # Also, consider making the extension search case-insensitive for robustness\n",
    "        for img_path in glob.iglob(\n",
    "            os.path.join(image_dir, f\"*.{image_ext}\"), recursive=True\n",
    "        ):\n",
    "            print(f\"Attempting to process: {img_path}\")  # Added for debugging\n",
    "\n",
    "            # Add error handling for image loading\n",
    "            try:\n",
    "                # Use a 'with' statement for safer file handling, though not strictly necessary for PIL's Image.open\n",
    "                with Image.open(img_path) as img:\n",
    "                    raw_image = img.convert(\"RGB\")\n",
    "\n",
    "                # You do not need a question for image captioning\n",
    "                inputs = processor(raw_image, return_tensors=\"pt\")\n",
    "\n",
    "                # Generate a caption for the image\n",
    "                # Consider adding a timeout or specific device if running into memory issues on large models\n",
    "                out = model.generate(**inputs, max_new_tokens=50)\n",
    "\n",
    "                # Decode the generated tokens to text\n",
    "                caption = processor.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "                # Write the caption to the file, prepended by the image file name\n",
    "                caption_file.write(f\"{os.path.basename(img_path)}: {caption}\\n\")\n",
    "                print(\n",
    "                    f\"Successfully captioned: {os.path.basename(img_path)}\"\n",
    "                )  # Added for debugging\n",
    "\n",
    "            except OSError as e:\n",
    "                # This catches the \"Invalid argument\" error and similar file-related issues\n",
    "                print(\n",
    "                    f\"ERROR: Could not open or process image {img_path}. Skipping. Error: {e}\"\n",
    "                )\n",
    "            except Exception as e:\n",
    "                # This catches any other unexpected errors during processing\n",
    "                print(\n",
    "                    f\"An unexpected error occurred with image {img_path}. Skipping. Error: {e}\"\n",
    "                )\n",
    "\n",
    "print(\"Captioning process complete.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
