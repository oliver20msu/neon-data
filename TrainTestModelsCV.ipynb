{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "163ff8e9-6e9d-42c3-9638-d9fe4f7a4e5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m.\u001b[39mdescribe()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.info() # Gives concise summary of dataset\n",
    "df.head(n) # Gives first n rows of dataset\n",
    "df.describe() # Gives descriptives\n",
    "df.describe(include = 'all') # Gives descriptives on all columns incl non INT\n",
    "df_test = df[['body-style','price']] # and...\n",
    "ef_grp = df_test.groupby(['body-style'], as_index = false).mean() # Gives averages grouped by body style\n",
    "df['body-style'] # Accesses column 'body-style' from dataframe\n",
    "df.rename(columns = {'city': 'Cities'}, inplace = True) # Renames column 'city' to 'Cities'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c57d3a1-d2c9-4675-8d8e-ea859241686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression lm=LinearRegression()\n",
    "X = df[['highway-mpg']]\n",
    "Y = df['price']\n",
    "lm.fit(X, Y)\n",
    "Yhat=lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70b7c2-1334-4d00-9030-15ec46f75b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of determination\n",
    "\n",
    "lm = LinearRegression()\n",
    "X = df[['highway-mpg']]\n",
    "Y = df['price']\n",
    "lm.fit(X, Y)\n",
    "out=lm.score(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a5d583-f213-46f7-9f18-edcdc5c9a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train-test groups\n",
    "\n",
    "train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48364304-2869-4d95-9a80-0a75669ec319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into n folds for cross validation return x on y predictions for all three folds /\n",
    "# Concatenate, each y getting a new prediction for an x it didn't train on\n",
    "\n",
    "cross_val_predict (lr2e, x_data, y_data, cv=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a57393-7b4d-4959-b824-e6cf2f7486e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full train-tests with visualization\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# --- Python Cheat Sheet for Train-Test Split and Model Evaluation ---\n",
    "\n",
    "# Assuming you have a pandas DataFrame named 'df' with your variables X and Y\n",
    "\n",
    "# 1. Define X (features) and Y (target)\n",
    "#    Replace 'feature_column_1', 'feature_column_2', and 'target_column' with your actual column names\n",
    "X = df[['feature_column_1', 'feature_column_2']] # Example for multiple features\n",
    "Y = df['target_column'] # Your target variable\n",
    "\n",
    "# If X is a single feature, it's good practice to reshape it to a 2D array\n",
    "# X = df[['single_feature_column']]\n",
    "\n",
    "# 2. Train-Test Split\n",
    "#    test_size: Proportion of the dataset to include in the test split (e.g., 0.2 for 20%)\n",
    "#    random_state: Ensures reproducibility of your split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"Y_train shape: {Y_train.shape}\")\n",
    "print(f\"Y_test shape: {Y_test.shape}\")\n",
    "\n",
    "# 3. Basic Linear Regression Model (as an example)\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE)\n",
    "mse_train = mean_squared_error(Y_train, Y_train_pred)\n",
    "mse_test = mean_squared_error(Y_test, Y_test_pred)\n",
    "\n",
    "print(f\"\\n--- Basic Linear Regression Results ---\")\n",
    "print(f\"Train MSE: {mse_train:.4f}\")\n",
    "print(f\"Test MSE: {mse_test:.4f}\")\n",
    "\n",
    "# 4. Alpha Tests for Over/Underfitting (using MSE comparison)\n",
    "\n",
    "print(f\"\\n--- Alpha Tests for Over/Underfitting ---\")\n",
    "# Rule of Thumb:\n",
    "# If Train MSE is significantly lower than Test MSE: Potential Overfitting\n",
    "# If both Train MSE and Test MSE are high and similar: Potential Underfitting\n",
    "# If both Train MSE and Test MSE are low and similar: Good Fit\n",
    "\n",
    "# Define a threshold for \"significant difference\" (can be adjusted)\n",
    "threshold = 0.1 * mse_train # Example: 10% difference from train MSE\n",
    "\n",
    "if abs(mse_train - mse_test) > threshold and mse_train < mse_test:\n",
    "    print(\"WARNING: Potential Overfitting! Train MSE is significantly lower than Test MSE.\")\n",
    "elif mse_train > (mse_test * 1.5) and mse_test > np.mean(Y_train)**2: # Heuristic for high MSE\n",
    "    print(\"WARNING: Potential Underfitting! Both Train and Test MSE are high, and relatively similar.\")\n",
    "else:\n",
    "    print(\"Model appears to have a reasonable fit (neither severely overfit nor underfit).\")\n",
    "print(f\"MSE Difference (Train - Test): {mse_train - mse_test:.4f}\")\n",
    "\n",
    "\n",
    "# 5. MSE/Polynomial-Order Graph for Determining Best Fit\n",
    "\n",
    "# This section assumes X is a single feature for visualization purposes.\n",
    "# If X has multiple features, you might want to perform dimensionality reduction\n",
    "# or plot against a single dominant feature.\n",
    "\n",
    "if X.shape[1] > 1:\n",
    "    print(\"\\nNote: For the Polynomial Order Graph, it's best suited for single features.\")\n",
    "    print(\"Consider using a single dominant feature from X or dimensionality reduction.\")\n",
    "    # For demonstration, we'll pick the first feature if multiple exist.\n",
    "    X_single_feature = X.iloc[:, 0].values.reshape(-1, 1)\n",
    "    X_train_poly, X_test_poly, Y_train_poly, Y_test_poly = train_test_split(\n",
    "        X_single_feature, Y, test_size=0.2, random_state=42\n",
    "    )\n",
    "else:\n",
    "    X_train_poly, X_test_poly, Y_train_poly, Y_test_poly = X_train, X_test, Y_train, Y_test\n",
    "\n",
    "\n",
    "max_degree = 10 # Maximum polynomial degree to test\n",
    "train_mse_errors = []\n",
    "test_mse_errors = []\n",
    "polynomial_degrees = range(1, max_degree + 1)\n",
    "\n",
    "for degree in polynomial_degrees:\n",
    "    poly_features = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly_transformed = poly_features.fit_transform(X_train_poly)\n",
    "    X_test_poly_transformed = poly_features.transform(X_test_poly)\n",
    "\n",
    "    poly_model = LinearRegression()\n",
    "    poly_model.fit(X_train_poly_transformed, Y_train_poly)\n",
    "\n",
    "    Y_train_pred_poly = poly_model.predict(X_train_poly_transformed)\n",
    "    Y_test_pred_poly = poly_model.predict(X_test_poly_transformed)\n",
    "\n",
    "    train_mse_errors.append(mean_squared_error(Y_train_poly, Y_train_pred_poly))\n",
    "    test_mse_errors.append(mean_squared_error(Y_test_poly, Y_test_pred_poly))\n",
    "\n",
    "# Plotting the MSE vs. Polynomial Order\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(polynomial_degrees, train_mse_errors, label='Train MSE', marker='o')\n",
    "plt.plot(polynomial_degrees, test_mse_errors, label='Test MSE', marker='o')\n",
    "plt.xlabel('Polynomial Order')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('MSE vs. Polynomial Order to Determine Best Fit')\n",
    "plt.xticks(polynomial_degrees)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.axvline(x=np.argmin(test_mse_errors) + 1, color='red', linestyle='--', label='Optimal Test MSE')\n",
    "plt.text(np.argmin(test_mse_errors) + 1 + 0.2, min(test_mse_errors),\n",
    "         f'Best Degree: {np.argmin(test_mse_errors) + 1}', color='red')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n--- Polynomial Order Analysis ---\")\n",
    "optimal_degree_index = np.argmin(test_mse_errors)\n",
    "optimal_degree = polynomial_degrees[optimal_degree_index]\n",
    "print(f\"The polynomial order with the lowest Test MSE is: {optimal_degree}\")\n",
    "print(f\"Corresponding Train MSE: {train_mse_errors[optimal_degree_index]:.4f}\")\n",
    "print(f\"Corresponding Test MSE: {test_mse_errors[optimal_degree_index]:.4f}\")\n",
    "\n",
    "# Re-evaluating alpha tests for the optimal polynomial model\n",
    "if abs(train_mse_errors[optimal_degree_index] - test_mse_errors[optimal_degree_index]) > threshold and \\\n",
    "   train_mse_errors[optimal_degree_index] < test_mse_errors[optimal_degree_index]:\n",
    "    print(\"WARNING: Potential Overfitting with optimal polynomial degree.\")\n",
    "elif train_mse_errors[optimal_degree_index] > (test_mse_errors[optimal_degree_index] * 1.5) and \\\n",
    "     test_mse_errors[optimal_degree_index] > np.mean(Y_train_poly)**2:\n",
    "    print(\"WARNING: Potential Underfitting with optimal polynomial degree.\")\n",
    "else:\n",
    "    print(\"Optimal polynomial model appears to have a reasonable fit.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
